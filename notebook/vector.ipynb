{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9900b361",
   "metadata": {},
   "source": [
    "# Doc file tu fol /processed_data\n",
    "# Duyet tung dong -> chuyen than vector \n",
    "# Luu voi format:\n",
    "\n",
    "{\n",
    "  \"chunks\": [\n",
    "    {\n",
    "      chunk_index: 1,\n",
    "      vector: [0.0910910239]\n",
    "    }\n",
    "  ],\n",
    "  // lUU CHO KHAC ... TOI UU. HOAC LA LUNG CHUNG LUON .\n",
    "  \"metadata\": { id, title, author, tags, publish_time...}\n",
    "}\n",
    "\n",
    "# Seach duoc - (Anh + Huy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4966f4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/dae4cf6d-35d6-4a5e-8ca3-b5ad6ef52795/py_env_research/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n",
    "model = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "\n",
    "\n",
    "# Test\n",
    "# if __name__ == '__main__':\n",
    "#     sample = \"Việt Nam vô địch AFF Cup\"\n",
    "#     vec = vectorize(sample)\n",
    "#     print(f\"Vector result: {vec}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c590c97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>picture_count</th>\n",
       "      <th>processed</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "      <th>url</th>\n",
       "      <th>crawled_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>218270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chiều 31/7 , công_an tỉnh thừa_thiên - huế đã ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>docbao.vn</td>\n",
       "      <td>Tên cướp tiệm vàng tại Huế là đại uý công an, ...</td>\n",
       "      <td>Pháp luật</td>\n",
       "      <td>https://docbao.vn/phap-luat/ten-cuop-tiem-vang...</td>\n",
       "      <td>2022-08-01 09:09:22.817308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>218269</td>\n",
       "      <td>(Nguồn: Sina)</td>\n",
       "      <td>gần đây , thứ_trưởng bộ phát_triển kỹ_thuật_số...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>vtc.vn</td>\n",
       "      <td>Bỏ qua mạng 5G, Nga tiến thẳng từ 4G lên 6G</td>\n",
       "      <td>Sống kết nối</td>\n",
       "      <td>https://vtc.vn/bo-qua-mang-5g-nga-tien-thang-t...</td>\n",
       "      <td>2022-08-01 09:09:21.181469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>218268</td>\n",
       "      <td>Hồ Sỹ Anh</td>\n",
       "      <td>kết_quả thi tốt_nghiệp thpt năm 2022 cho thấy ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>thanhnien.vn</td>\n",
       "      <td>Địa phương nào đứng đầu cả nước tổng điểm 3 mô...</td>\n",
       "      <td>Giáo dục</td>\n",
       "      <td>https://thanhnien.vn/dia-phuong-nao-dung-dau-c...</td>\n",
       "      <td>2022-08-01 09:09:15.311901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>218267</td>\n",
       "      <td>Ngọc Ánh</td>\n",
       "      <td>thống_đốc kentucky andy beshear hôm 31/7 cho_h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>vnexpress</td>\n",
       "      <td>Người chết trong mưa lũ 'nghìn năm có một' ở M...</td>\n",
       "      <td>Thế giới</td>\n",
       "      <td>https://vnexpress.net/nguoi-chet-trong-mua-lu-...</td>\n",
       "      <td>2022-08-01 09:09:02.211498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>218266</td>\n",
       "      <td>HẢI YẾN - MINH LÝ</td>\n",
       "      <td>vụ tai_nạn giao_thông liên_hoàn trên phố đi bộ...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>soha</td>\n",
       "      <td>Hải Phòng: Hình ảnh xe \"điên\" gây tai nạn liên...</td>\n",
       "      <td>Thời sự - Xã hội</td>\n",
       "      <td>https://soha.vn/hai-phong-hinh-anh-xe-dien-gay...</td>\n",
       "      <td>2022-08-01 09:09:01.601170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0      id             author  \\\n",
       "0          0  218270                NaN   \n",
       "1          1  218269      (Nguồn: Sina)   \n",
       "2          2  218268          Hồ Sỹ Anh   \n",
       "3          3  218267           Ngọc Ánh   \n",
       "4          4  218266  HẢI YẾN - MINH LÝ   \n",
       "\n",
       "                                             content picture_count processed  \\\n",
       "0  chiều 31/7 , công_an tỉnh thừa_thiên - huế đã ...             3         0   \n",
       "1  gần đây , thứ_trưởng bộ phát_triển kỹ_thuật_số...             1         0   \n",
       "2  kết_quả thi tốt_nghiệp thpt năm 2022 cho thấy ...             3         0   \n",
       "3  thống_đốc kentucky andy beshear hôm 31/7 cho_h...             1         0   \n",
       "4  vụ tai_nạn giao_thông liên_hoàn trên phố đi bộ...            12         0   \n",
       "\n",
       "         source                                              title  \\\n",
       "0     docbao.vn  Tên cướp tiệm vàng tại Huế là đại uý công an, ...   \n",
       "1        vtc.vn        Bỏ qua mạng 5G, Nga tiến thẳng từ 4G lên 6G   \n",
       "2  thanhnien.vn  Địa phương nào đứng đầu cả nước tổng điểm 3 mô...   \n",
       "3     vnexpress  Người chết trong mưa lũ 'nghìn năm có một' ở M...   \n",
       "4          soha  Hải Phòng: Hình ảnh xe \"điên\" gây tai nạn liên...   \n",
       "\n",
       "              topic                                                url  \\\n",
       "0         Pháp luật  https://docbao.vn/phap-luat/ten-cuop-tiem-vang...   \n",
       "1      Sống kết nối  https://vtc.vn/bo-qua-mang-5g-nga-tien-thang-t...   \n",
       "2          Giáo dục  https://thanhnien.vn/dia-phuong-nao-dung-dau-c...   \n",
       "3          Thế giới  https://vnexpress.net/nguoi-chet-trong-mua-lu-...   \n",
       "4  Thời sự - Xã hội  https://soha.vn/hai-phong-hinh-anh-xe-dien-gay...   \n",
       "\n",
       "                   crawled_at  \n",
       "0  2022-08-01 09:09:22.817308  \n",
       "1  2022-08-01 09:09:21.181469  \n",
       "2  2022-08-01 09:09:15.311901  \n",
       "3  2022-08-01 09:09:02.211498  \n",
       "4  2022-08-01 09:09:01.601170  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đường dẫn file dữ liệu gốc và file đầu ra\n",
    "BASE_OUTPUT_DATA_DIR = \"../data/processed_data/Original_news_dataset.csv\"\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "df = pd.read_csv(BASE_OUTPUT_DATA_DIR, dtype=str, nrows=2000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0302dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sentences(sentences, max_tokens=256):\n",
    "  chunks = []\n",
    "  current_chunk = []\n",
    "  current_length = 0\n",
    "\n",
    "  for sentence in sentences:\n",
    "    if not sentence:\n",
    "      continue\n",
    "    tokenized = tokenizer.tokenize(sentence)\n",
    "    token_length = len(tokenized)\n",
    "\n",
    "    if token_length >= max_tokens:\n",
    "      # Nếu câu này đã >= max_tokens thì tách riêng, không ghép thêm\n",
    "      if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "        current_chunk = []\n",
    "        current_length = 0\n",
    "      chunks.append(sentence)\n",
    "    else:\n",
    "      if current_length + token_length <= max_tokens:\n",
    "        current_chunk.append(sentence)\n",
    "        current_length += token_length\n",
    "      else:\n",
    "        if current_chunk:\n",
    "          chunks.append(\" \".join(current_chunk))\n",
    "        current_chunk = [sentence]\n",
    "        current_length = token_length\n",
    "\n",
    "  if current_chunk:\n",
    "    chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "  return chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0885d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyen content -> vector\n",
    "from underthesea import sent_tokenize\n",
    "\n",
    "def vectorize(text):\n",
    "    tokens = tokenizer(text, return_tensors='pt',  \n",
    "                       truncation=True, padding='max_length', max_length=258)\n",
    "    with torch.no_grad(): \n",
    "      \n",
    "        outputs = model(**tokens)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().tolist()\n",
    "\n",
    "def process_content(sentences):\n",
    "    # sentences = sent_tokenize(content\n",
    "    # print(sentences)\n",
    "    chunks = merge_sentences(sentences)\n",
    "    vectors = [vectorize(chunk) for chunk in chunks]\n",
    "    # vectors = [vectorize(chunk) for chunk in sentences]\n",
    "    return vectors\n",
    "# fj\n",
    "\n",
    "output_data = []\n",
    "\n",
    "for idx, row in df.head(10).iterrows():\n",
    "  content = row['content']\n",
    "  if pd.isnull(content):\n",
    "    continue\n",
    "  \n",
    "  ## \n",
    "  sentences = content.split('.')\n",
    "  vectors = process_content(sentences)\n",
    "  \n",
    "  chunks = []\n",
    "  # Bien doi thanh JSON\n",
    "  for i, vector in enumerate(vectors):\n",
    "    chunks.append({\n",
    "      \"chunk_index\": i + 1,\n",
    "      \"vector\": vector,\n",
    "      \"text\": sentences[i] if i < len(sentences) else \"\"\n",
    "    })\n",
    "  metadata = {\n",
    "    \"id\": row['id'],\n",
    "    \"title\": row['title'],\n",
    "    \"author\": row['author'],\n",
    "    \"tags\": row['topic'],\n",
    "    \"publish_time\": row['crawled_at'],\n",
    "    \"source\": row['source'],\n",
    "    \"url\": row['url']\n",
    "  }\n",
    "  output_data.append({\n",
    "    \"chunks\": chunks,\n",
    "    \"metadata\": metadata\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82e343ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"output_vectors.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "  json.dump(output_data, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b04ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting qdrant_client\n",
      "  Downloading qdrant_client-1.14.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting grpcio>=1.41.0 (from qdrant_client)\n",
      "  Downloading grpcio-1.73.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting httpx>=0.20.0 (from httpx[http2]>=0.20.0->qdrant_client)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in /mnt/dae4cf6d-35d6-4a5e-8ca3-b5ad6ef52795/py_env_research/.venv/lib/python3.11/site-packages (from qdrant_client) (2.3.1)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant_client)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting protobuf>=3.20.0 (from qdrant_client)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 (from qdrant_client)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /mnt/dae4cf6d-35d6-4a5e-8ca3-b5ad6ef52795/py_env_research/.venv/lib/python3.11/site-packages (from qdrant_client) (2.5.0)\n",
      "Collecting anyio (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi in /mnt/dae4cf6d-35d6-4a5e-8ca3-b5ad6ef52795/py_env_research/.venv/lib/python3.11/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (2025.6.15)\n",
      "Collecting httpcore==1.* (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in /mnt/dae4cf6d-35d6-4a5e-8ca3-b5ad6ef52795/py_env_research/.venv/lib/python3.11/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.10)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant_client)\n",
      "  Downloading h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client)\n",
      "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client)\n",
      "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /mnt/dae4cf6d-35d6-4a5e-8ca3-b5ad6ef52795/py_env_research/.venv/lib/python3.11/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (4.14.0)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading qdrant_client-1.14.3-py3-none-any.whl (328 kB)\n",
      "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading grpcio-1.73.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading h2-4.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: typing-inspection, sniffio, pydantic-core, protobuf, portalocker, hyperframe, hpack, h11, grpcio, annotated-types, pydantic, httpcore, h2, anyio, httpx, qdrant_client\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [qdrant_client]0m [qdrant_client]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.9.0 grpcio-1.73.1 h11-0.16.0 h2-4.2.0 hpack-4.1.0 httpcore-1.0.9 httpx-0.28.1 hyperframe-6.1.0 portalocker-2.10.1 protobuf-6.31.1 pydantic-2.11.7 pydantic-core-2.33.2 qdrant_client-1.14.3 sniffio-1.3.1 typing-inspection-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90ee3546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_114990/3042891842.py:12: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "\n",
    "# Use in-memory Qdrant instance\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "collection_name = \"news_vectors_v4\"\n",
    "\n",
    "# Tạo collection nếu chưa có\n",
    "if collection_name not in [c.name for c in client.get_collections().collections]:\n",
    "  client.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "      size=len(output_data[0]['chunks'][0]['vector']),\n",
    "      distance=\"Cosine\",\n",
    "    )\n",
    "  )\n",
    "\n",
    "# Lưu vectors vào Qdrant\n",
    "for item in output_data:\n",
    "  points = []\n",
    "  for chunk in item[\"chunks\"]:\n",
    "    points.append(\n",
    "      models.PointStruct(\n",
    "        id=str(uuid4()),\n",
    "        vector=chunk[\"vector\"],\n",
    "        payload={\n",
    "          \"text\": chunk[\"text\"],\n",
    "          **item[\"metadata\"]\n",
    "        }\n",
    "      )\n",
    "    )\n",
    "  client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points,\n",
    "    \n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "849dd9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User query: binh_duong co_tong 3 mon_toan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_114990/991084370.py:15: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  query_result.dict()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'points': [{'id': 'a7e771c1-0389-43e3-b5e2-3b783a0bb259',\n",
       "   'version': 0,\n",
       "   'score': 0.6505497047340189,\n",
       "   'payload': {'text': ' ronaldo là cầu_thủ duy_nhất bị ten hag rút ra ngay sau giờ nghỉ , nhường chỗ cho amad diallo ',\n",
       "    'id': '218261',\n",
       "    'title': 'Bị thay sau hiệp 1, Ronaldo đùng đùng bỏ về sớm',\n",
       "    'author': 'Đỗ Trung',\n",
       "    'tags': 'Ngoại hạng Anh',\n",
       "    'publish_time': '2022-08-01 09:08:42.496092',\n",
       "    'source': 'bongdaplus',\n",
       "    'url': 'https://bongdaplus.vn/ngoai-hang-anh/ronaldo-dung-dung-bo-ve-som-3726962208.html'},\n",
       "   'vector': None,\n",
       "   'shard_key': None,\n",
       "   'order_value': None},\n",
       "  {'id': '1bad41ad-3e84-45e1-8b52-d6cd9d781374',\n",
       "   'version': 0,\n",
       "   'score': 0.5914473290531295,\n",
       "   'payload': {'text': '',\n",
       "    'id': '218268',\n",
       "    'title': 'Địa phương nào đứng đầu cả nước tổng điểm 3 môn văn, toán, ngoại ngữ?',\n",
       "    'author': 'Hồ Sỹ Anh',\n",
       "    'tags': 'Giáo dục',\n",
       "    'publish_time': '2022-08-01 09:09:15.311901',\n",
       "    'source': 'thanhnien.vn',\n",
       "    'url': 'https://thanhnien.vn/dia-phuong-nao-dung-dau-ca-nuoc-tong-diem-3-mon-van-toan-ngoai-ngu-post1483653.html'},\n",
       "   'vector': None,\n",
       "   'shard_key': None,\n",
       "   'order_value': None},\n",
       "  {'id': '60a9ccc6-15d0-4f62-af83-8890c88ceca2',\n",
       "   'version': 0,\n",
       "   'score': 0.5766119366596892,\n",
       "   'payload': {'text': ' nhiều ngôi nhà ở kentucky đã bị lũ cuốn trôi sau những ngày mưa lớn mà thống_đốc beshear miêu_tả là \" một trong những điều tồi_tệ nhất trong lịch_sử bang \" ',\n",
       "    'id': '218267',\n",
       "    'title': \"Người chết trong mưa lũ 'nghìn năm có một' ở Mỹ tăng lên 28\",\n",
       "    'author': 'Ngọc Ánh',\n",
       "    'tags': 'Thế giới',\n",
       "    'publish_time': '2022-08-01 09:09:02.211498',\n",
       "    'source': 'vnexpress',\n",
       "    'url': 'https://vnexpress.net/nguoi-chet-trong-mua-lu-nghin-nam-co-mot-o-my-tang-len-28-4494262.html'},\n",
       "   'vector': None,\n",
       "   'shard_key': None,\n",
       "   'order_value': None}]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from underthesea import word_tokenize\n",
    "from qdrant_client.models import Filter, FieldCondition, MatchValue\n",
    "\n",
    "\n",
    "user_query = word_tokenize(\"Binh Duong co tong 3 mon toan\".strip().lower(), format=\"text\")\n",
    "print(f\"User query: {user_query}\")\n",
    "user_query_vector = vectorize(user_query)\n",
    "query_result = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=user_query_vector,\n",
    "    limit=3, \n",
    "    with_payload=True,\n",
    ")\n",
    "\n",
    "query_result.dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
